{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dr. Chakra Chennubhotla Lab -\n",
    "### add details here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import dgl\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dgl.data.utils import save_graphs\n",
    "from dgl.data.utils import load_graphs\n",
    "\n",
    "import sklearn\n",
    "import pickle \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import imageio\n",
    "import cv2\n",
    "import matplotlib as mpl;\n",
    "from matplotlib import cm\n",
    "import pickle as pkl\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "from scipy.io import loadmat # Added package\n",
    "from shapely.geometry import Polygon, MultiPolygon, Point # Added package\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "from scipy.interpolate import splprep, splev, CubicSpline\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from collections import defaultdict\n",
    "from PIL import Image, ImageDraw\n",
    "from scipy.ndimage.measurements import label\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "from networkx import draw\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from scipy import io\n",
    "from sklearn import metrics\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "import random\n",
    "\n",
    "import os.path\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1,'gnn-min-example-master/')\n",
    "import torch.utils.data\n",
    "\n",
    "from core.dataloader.constants import TRAIN_RATIO, TEST_RATIO\n",
    "from core.utils import read_params\n",
    "from core.model import Model\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(feats_path, imagename, k_nearest, dmin):\n",
    "    \n",
    "    if os.path.isfile(feats_path+imagename+'_mask_measurements.csv') == True:\n",
    "        nuclei_metrics = pd.read_csv(feats_path+imagename+'_mask_measurements.csv') \n",
    "    elif os.path.isfile(feats_path+imagename+'_measurements.csv') == True:\n",
    "        nuclei_metrics = pd.read_csv(feats_path+imagename+'_measurements.csv') \n",
    "        \n",
    "    fcg = nuclei_metrics.drop([' ', 'Label', '%Area', 'StdDev', 'Min', 'Max', 'Median', 'Skew', 'Kurt', 'X', 'Y'], 1)\n",
    "    #fcg = nuclei_metrics.drop(['X', 'Y'], 1)\n",
    "    print(nuclei_metrics.shape[0])\n",
    "    while(nuclei_metrics.empty != True and nuclei_metrics.shape[0] >=50):\n",
    "    \n",
    "        xcoords = np.asarray(nuclei_metrics['X'])\n",
    "        ycoords = np.asarray(nuclei_metrics['Y'])\n",
    "\n",
    "        # dmin = 50 pixels\n",
    "        # k = 5\n",
    "        # build the graph - CG by connecting atmost 5 nearest nuclei which is no greater than 50 pixels apart\n",
    "\n",
    "        coords = np.zeros((xcoords.shape[0],2))\n",
    "        coords[:,0] = xcoords\n",
    "        coords[:,1] = ycoords\n",
    "\n",
    "        dist_nuc = distance.squareform(distance.pdist(coords))\n",
    "        dist_nuc_sorted = np.sort(dist_nuc, axis=1)\n",
    "\n",
    "        closest = np.argsort(dist_nuc, axis=1)\n",
    "        k_closest = np.zeros((k_nearest, closest.shape[1]))\n",
    "        k_closest = closest[:,1:k_nearest+1]\n",
    "\n",
    "        # get 5 closest distances\n",
    "\n",
    "        k_distance = dist_nuc_sorted[:,0:k_nearest+1]\n",
    "\n",
    "        src = []\n",
    "        dst = []\n",
    "        \n",
    "        aa = []\n",
    "        for i in range(fcg.shape[0]):\n",
    "\n",
    "            for j in range(k_nearest):\n",
    "\n",
    "                # check if nucleus if more than 50 pixels away (dmin)\n",
    "\n",
    "                if k_distance[i,j] <= dmin:\n",
    "\n",
    "                    src.append(i);\n",
    "                    dst.append(k_closest[i,j])\n",
    "\n",
    "        u = np.concatenate([src, dst])\n",
    "        v = np.concatenate([dst, src])\n",
    "        u = u.astype(np.int32)\n",
    "        v = v.astype(np.int32)\n",
    "        \n",
    "        G = dgl.graph((u, v))\n",
    "\n",
    "        cell_features = torch.tensor(fcg.values)\n",
    "        cell_features = cell_features.float()\n",
    "        \n",
    "        G.ndata['feat'] = cell_features\n",
    "    \n",
    "        return G\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, val, and test data ready for dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = '/home/akashparvatikar/Documents/cvpr/data/'\n",
    "\n",
    "# get image list for train, val, and test\n",
    "train = pd.read_csv(label_path+'tf_train.csv')\n",
    "val   = pd.read_csv(label_path+'tf_val.csv')\n",
    "test  = pd.read_csv(label_path+'tf_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load train labels and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train['Image'])\n",
    "train_labels = train['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data_invasive', 'rb') as config_dictionary_file:\n",
    "    train_data = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load validation labels and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = np.array(val['Image'])\n",
    "val_labels = val['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_data_invasive', 'rb') as config_dictionary_file:\n",
    "    val_data = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Load test labels and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.array(test['Image'])\n",
    "test_labels = test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data_invasive', 'rb') as config_dictionary_file:\n",
    "    test_data = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CG-GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_loader(dataset_train,dataset_val,dataset_test, batch_size, cuda, gpu):\n",
    "\n",
    "    preprocess(dataset_train, cuda)\n",
    "    preprocess(dataset_val, cuda)\n",
    "    preprocess(dataset_test, cuda)\n",
    "    \n",
    "    rank = args.nr * args.gpus + gpu\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset_train,num_replicas=args.world_size,rank=rank)\n",
    "    val_sampler = torch.utils.data.distributed.DistributedSampler(dataset_val,num_replicas=args.world_size,rank=rank)\n",
    "    test_sampler = torch.utils.data.distributed.DistributedSampler(dataset_test,num_replicas=args.world_size,rank=rank)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset_train,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=False,\n",
    "                                                   collate_fn=collate, num_workers=0, pin_memory=True, \n",
    "                                                   sampler=train_sampler)\n",
    "\n",
    "    val_dataloader = torch.utils.data.DataLoader(dataset_val,\n",
    "                                                 batch_size=batch_size, \n",
    "                                                 shuffle=False,\n",
    "                                                 collate_fn=collate, num_workers=0, pin_memory=True, \n",
    "                                                 sampler=val_sampler)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(dataset_test,\n",
    "                                                  batch_size=batch_size, \n",
    "                                                  shuffle=False,\n",
    "                                                  collate_fn=collate, num_workers=0, pin_memory=True, \n",
    "                                                  sampler=test_sampler)\n",
    "                                                  \n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(data):\n",
    "    \"\"\"\n",
    "    Collate function\n",
    "    \"\"\"\n",
    "    graphs, labels = map(list, zip(*data))\n",
    "    batched = dgl.batch(graphs)\n",
    "    labels = torch.LongTensor(labels)\n",
    "    return batched, labels\n",
    "\n",
    "\n",
    "def preprocess(dataset, cuda):\n",
    "\n",
    "    for g, _ in dataset:\n",
    "        g,_ = g.to('cuda:0'), _.to('cuda:0')\n",
    "        for key_g, val_g in g.ndata.items():\n",
    "            processed = g.ndata.pop(key_g)\n",
    "            processed = processed.type('torch.FloatTensor')\n",
    "            if cuda:\n",
    "                processed = processed.cuda()\n",
    "            g.ndata[key_g] = processed\n",
    "        for key_g, val_g in g.edata.items():\n",
    "            processed = g.edata.pop(key_g)\n",
    "            processed = processed.type('torch.FloatTensor')\n",
    "            if cuda:\n",
    "                processed = processed.cuda()\n",
    "            g.edata[key_g] = processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run GNN main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Run model script.\n",
    "\"\"\"\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from core.utils import read_params\n",
    "from core.model import Model\n",
    "\n",
    "\n",
    "def main(gpu, args):\n",
    "    \n",
    "    ############################################################\n",
    "    rank = args.nr * args.gpus + gpu                         \n",
    "    dist.init_process_group(backend='nccl', init_method='env://', world_size=args.world_size, rank=rank)\n",
    "    ############################################################\n",
    "    \n",
    "    config_params = read_params(args.config_fpath)\n",
    "    \n",
    "    if args.gpu < 0:\n",
    "        cuda = False\n",
    "    else:\n",
    "        cuda = True\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        \n",
    "    SAVE_DIR = 'models'\n",
    "    MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'mlp-cgnn_v2_invasive.pt')\n",
    "    \n",
    "    if not os.path.isdir(f'{SAVE_DIR}'):\n",
    "        os.makedirs(f'{SAVE_DIR}')\n",
    "            \n",
    "    best_valid_loss = float('inf')\n",
    "    \n",
    "    print('*** Create data loader ***')\n",
    "    dataloader, val_dataloader, test_dataloader = make_data_loader(train_data, val_data\n",
    "                                                               ,test_data, batch_size=16, cuda=True, gpu=gpu)\n",
    "    \n",
    "    print('*** Create model ***')\n",
    "    model = Model(config=config_params, verbose=True, cuda=cuda)\n",
    "    \n",
    "    print(cuda)\n",
    "    if cuda==True:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        \n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=args.lr,\n",
    "                                 weight_decay=args.weight_decay)\n",
    "    # loss function\n",
    "    loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Start training\n",
    "    print('*** Start training ***')\n",
    "    step = 0\n",
    "    model.train()\n",
    "    \n",
    "    # DDP\n",
    "    model = model.to(args.gpu)\n",
    "    model = nn.parallel.DistributedDataParallel(model.to(args.gpu), device_ids=[args.gpu])\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in range(args.n_epochs):\n",
    "        print(\"Epoch:\", epoch)\n",
    "        for iter, (graphs, labels) in enumerate(dataloader):\n",
    "            \n",
    "            # forward pass\n",
    "            graphs = graphs.to('cuda')\n",
    "            logits = model(graphs)\n",
    "            labels = labels.to('cuda')\n",
    "            # compute loss\n",
    "            loss = loss_fcn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # backpropagate\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # testing\n",
    "            step += 1\n",
    "            if step % args.eval_every == 0:\n",
    "                val_loss, val_acc = test(val_dataloader, model, loss_fcn)\n",
    "                print(\n",
    "                    \"Step {:05d} | Train loss {:.4f} | Over {} | Val loss {:.4f} |\"\n",
    "                    \"Val acc {:.4f}\".format(\n",
    "                        step,\n",
    "                        np.mean(losses),\n",
    "                        len(losses),\n",
    "                        val_loss,\n",
    "                        val_acc,\n",
    "                    ))\n",
    "                model.train()\n",
    "                \n",
    "                if val_loss < best_valid_loss:\n",
    "                    best_valid_loss = val_loss\n",
    "                    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "\n",
    "def test(data_loader, model, loss_fcn):\n",
    "    \"\"\"\n",
    "    Testing\n",
    "    :param data_loader: (data.Dataloader)\n",
    "    :param model: (Model)\n",
    "    :param loss_fcn: (torch.nn loss)\n",
    "    :return: loss, accuracy\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for iter, (graphs, labels) in enumerate(data_loader):\n",
    "\n",
    "        graphs = graphs.to('cuda')\n",
    "        logits = model(graphs)\n",
    "        labels = labels.to('cuda')\n",
    "        loss = loss_fcn(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        accuracies.append(correct.item() * 1.0 / len(labels))\n",
    "\n",
    "    return np.mean(losses), np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Create data loader ***\n",
      "*** Create model ***\n",
      "Creating GNN layers...\n",
      "Creating new GNN layer:\n",
      "MLP layer 0 has params Sequential(\n",
      "  (fc): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (bn): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "MLP layer 1 has params Sequential(\n",
      "  (fc): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (bn): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Creating new GNN layer:\n",
      "MLP layer 0 has params Sequential(\n",
      "  (fc): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (bn): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "MLP layer 1 has params Sequential(\n",
      "  (fc): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (bn): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Creating new GNN layer:\n",
      "MLP layer 0 has params Sequential(\n",
      "  (fc): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (bn): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "MLP layer 1 has params Sequential(\n",
      "  (fc): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (bn): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Creating readout function...\n",
      "MLP layer 0 has params Sequential(\n",
      "  (fc): Linear(in_features=42, out_features=64, bias=True)\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "MLP layer 1 has params Sequential(\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "True\n",
      "*** Start training ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Step 00050 | Train loss 0.5179 | Over 50 | Val loss 0.5764 |Val acc 0.7250\n",
      "Epoch: 2\n",
      "Step 00100 | Train loss 0.5039 | Over 100 | Val loss 0.5395 |Val acc 0.7188\n",
      "Epoch: 3\n",
      "Step 00150 | Train loss 0.4949 | Over 150 | Val loss 0.5285 |Val acc 0.7688\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Step 00200 | Train loss 0.4857 | Over 200 | Val loss 0.5930 |Val acc 0.6000\n",
      "Epoch: 6\n",
      "Step 00250 | Train loss 0.4790 | Over 250 | Val loss 0.5317 |Val acc 0.7438\n",
      "Epoch: 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17748/3512955273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MASTER_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'localhost'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MASTER_PORT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'8802'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#main(args)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17748/2595491439.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(gpu, args)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/cvpr/code/gnn/gnn-min-example-master/core/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graphs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# forward-pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m# update node features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/cvpr/code/gnn/gnn-min-example-master/core/layers/gnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0mnode\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \"\"\"\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_eps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   4684\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4685\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0metype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4686\u001b[0;31m         \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_passing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_node_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4687\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_n_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dgl/core.py\u001b[0m in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0morig_nid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvoke_udf_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_nid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig_nid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m     \u001b[0;31m# apply phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mafunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dgl/core.py\u001b[0m in \u001b[0;36minvoke_udf_reduce\u001b[0;34m(graph, func, msgdata, orig_nid)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# order the incoming edges per node by edge ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0meid_bkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzerocopy_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_bkt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meid_bkt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdeg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_bkt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0meid_bkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meid_bkt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_bkt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36min_edges\u001b[0;34m(self, v, form, etype)\u001b[0m\n\u001b[1;32m   3167\u001b[0m         \"\"\"\n\u001b[1;32m   3168\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3169\u001b[0;31m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_etype_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3171\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dgl/heterograph_index.py\u001b[0m in \u001b[0;36min_edges\u001b[0;34m(self, etype, v)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0medge\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0medge_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CAPI_DGLHeteroInEdges_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dgl_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dgl_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dgl_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    class Args:\n",
    "        \n",
    "        lr = 1e-3\n",
    "        weight_decay = 5e-4\n",
    "        n_epochs = 10\n",
    "        batch_size = 16\n",
    "        eval_every = 50\n",
    "        config_fpath = 'gnn-min-example-master/core/config/config_file_binary.json'\n",
    "        gpu=0\n",
    "        \n",
    "        # DDP\n",
    "        gpus = 1\n",
    "        nodes = 1\n",
    "        nr = 0\n",
    "        world_size = gpus * nodes\n",
    "    \n",
    "    \n",
    "    args = Args()\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '8802' \n",
    "    mp.spawn(main(0,args), nprocs= gpus, args = Args())\n",
    "    \n",
    "    #main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# destroy WORLD process if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.destroy_process_group()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
